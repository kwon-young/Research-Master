\documentclass[11pt]{sdm}
\usepackage{graphicx}

%numeroter les pages
\pagestyle{plain}

\title{Segmentation and recognition of symbols for printed and handwritten music scores}
\author{Kwon-Young \textsc{Choi}}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\supervisorOne{Bertrand \textsc{Coüasnon}}
\supervisorTwo{Yann \textsc{Ricquebourg}}
\supervisorTwo{Richard \textsc{Zanibbi}}
\team{Intuidoc}
%One of:
% ens-Rennes  esir    insa-rennes logoENIB  rennes1  UBO
% enssat header logo_ENIB   logoUbs   tel-br supelec

\school{logo_ENIB}


% the domain should be one or two of:
% Technology for Human Learning
% Artificial Intelligence
% Computer Arithmetic
% Hardware Architecture
% Automatic Control Engineering
% Bioinformatics
% Biotechnology
% Computational Complexity
% Computational Engineering, Finance, and Science
% Computational Geometry
% Computation and Language
% Cryptography and Security
% Computer Vision and Pattern Recognition
% Computers and Society
% Databases
% Distributed, Parallel, and Cluster Computing
% Digital Libraries
% Discrete Mathematics
% Data Structures and Algorithms
% Embedded Systems
% Emerging Technologies
% Formal Languages and Automata Theory
% General Literature
% Graphics
% Computer Science and Game Theory
% Human-Computer Interaction
% Computer Aided Engineering
% Medical Imaging
% Information Retrieval
% Information Theory
% Ubiquitous Computing
% Machine Learning
% Logic in Computer Science
% Multiagent Systems
% Mobile Computing
% Multimedia
% Modeling and Simulation
% Mathematical Software
% Numerical Analysis
% Neural and Evolutionary Computing
% Networking and Internet Architecture
% Operating Systems
% Performance
% Programming Languages
% Robotics
% Operations Research
% Symbolic Computation
% Sound
% Software Engineering
% Social and Information Networks
% Systems and Control
% Image Processing
% Signal and Image Processing
% Document and Text Processing
% Web
\domain{Domain:  Document and Text Processing, Computer Vision and Pattern Recognition}

%write your abstract here
\abstract{write your abstract here}



\begin{document}
\maketitle

%*****************************************************************%

\section{Introduction}

The research team Intuidoc from the Irisa laboratory has developed a generic way of recognizing structured document by using the DMOS system.
The goal of this internship is to improve this generic document recognition method on the specific use of Optical Music Recognition (OMR).
The team has already formalized music notation grammar into rules understandable by the DMOS system.
But there are still problems during the low-level image recognition task.
Indeed, because of the density of information in a musical score and because of all preprocessing phases applied to the image, there are often cases of broken and overlapping musical symbols.
Currently, the recognition system used in DMOS is having difficulties in recognizing such symbols.
The specific purpose of this internship is to improve the recognition of broken and overlapping symbols.
The hypothesis that will guide this bibliography is that by avoiding explicit segmentation during the recognition phase, we will be able to improve the recognition task.
In a way, we are following the history of OCR and speech recognition where we have first used techniques with explicit segmentation, but now we have developed techniques that integrate segmentation in the recognition task.
Making generic method is an important characteristics of the DMOS philosophy, so although we are working on the music score, the improvement proposed should work for other structured documents.

We will first review the state of the art of OMR by first introducing how a music score is structured, then we will review the state of the art of OMR by presenting all steps classically used in OMR: preprocessing, staff removal, segmentation and recognition of music symbols, music notation reconstruction.
In a second part we will review different techniques that may improve the segmentation and recognition of music symbols.
Techniques that merge the segmentation and recognition task: Hidden Markov Model, Multi-Dimensional Long Short-Term Memory Recurrent Neural Network.
Finally, we will present other techniques used in image recognition like Convolutional Neural Network and a model of Visual Attention.

\section{State of the art of OMR}


In this section we will first define what is optical music recognition and its main issues.
Then we will describe all the steps commonly used for implementing an OMR system.
Finally, we will also briefly introduce the DMOS system developed by the intuidoc team in the context of OMR.


\subsection{Definition}


Nowadays, digitalizing scores is a common practice to save and share music.
But the format of these documents cannot be directly interpreted by a computer.
That is why we have developed Optical Music Recognition systems for converting an image of a score to a format that are understandable by a computer.
This computer vision task could be therefore classified as a hybrid domain between Optical Character Recognition and image recognition.
OMR is principally used to save time because manually transcribing a score in machine readable format is very time consuming.
Many music composers still find awkward to directly write music with a music composer software and prefer to write their music on paper.
The use of OMR in these situations could integrate into the working flow of music composer their habit to write music on paper and automatically transcribe them in a computer readable format.


A score is a structured document used to formalize music.
Its organization is hierarchical:
\begin{itemize}
  \item Different staffs are used for different instruments or voices.
  \item Each staffs can contain one or more bar lines.
  \item A bar line lines contain musical symbols.
  \item A music symbols like a note is constructed by the association of graphical primitives like a dot, stem and flags \ldots
\end{itemize}
There are multiple symbols in musical notation: clefs, notes and rests, breaks, accidentals and key signatures, time signatures, dynamics \ldots


OMR system are faced with multiple problems such as:
\begin{itemize}
  \item The high density of symbols
  \item High connectivity between symbols
  \item High variation of symbols
  \item Overlapping and broken symbols
\end{itemize}
A score has a unidirectional direction of reading that correspond to the time flow, but multiple things can happen simultaneously.
As a consequence, the output of an OMR system is not just a one dimensional sequence of symbols.
All graphical symbols must be localized horizontally and vertically in order to deduce their relations between each others.
% compléter par des illustrations


Authors like in \cite{rebelo_optical_2012} or \cite{fornes_analysis_2014} generally describe an OMR system by identifying multiple steps:
\begin{itemize}
  \item preprocessing
  \item staff removal
  \item symbol segmentation
  \item symbol recognition
  \item music score reconstruction
\end{itemize}
We will first review all these different steps, but we will particularly focus on symbol segmentation and recognition because it is the central theme of this internship.
We will also present more in details the DMOS system at the end of this part because of its role in this internship.


\subsection{Different step of OMR}


\subsubsection{Preprocessing}


The preprocessing phase of OMR consist of making some operation on the raw image to ease the latter steps of OMR.
Before anything, the image has to be converted into a binary image.
This operation is a classical operation of computer vision tasks.
Then, optional operation can be applied to enhance the quality of the score.
\begin{itemize}
  \item skew correction for staff line: used for simplifying the staff removal step.
  \item noise removal for bad scanning and digitalization.
  \item some other morphological operation \ldots
\end{itemize}

\subsubsection{Staff removal}

One characteristics of a music score is that most of the symbols are connected by the five bar lines that constitute a staff.
These bar lines are an obstacle for almost every classical techniques of segmentation and recognition used in computer vision.
This is why, most OMR systems first removes these lines.

A fast way to do this tasks is to do horizontal projection of a music staff.
The resulting vertical position of an intensity peak is an indicator of the position of a bar line.
It is worth noting that these kind of projection or run lengths techniques do not deal well with overlapping symbol, and often result on breaking symbols.
Candidate assemblage and contour tracking are an other way to remove a staff that are relatively fast to compute and can sometimes deal with overlapping symbols.
Graph path search techniques can produce really good results but are slow to compute.
Finally, detection of lines in an image can be done by using complex filters like a hough transform or a Kallman filter like one used in the DMOS system \cite{couasnon_dmos_2001}.



\subsubsection{Music symbol segmentation and recognition}


Music symbol segmentation and recognition are the core part of an OMR system.
It is also the more challenging part because of the high number and high variability of music symbols.
This complexity is often aggravated because of bad digitalization and paper degradation for ancient score.

Techniques used by OMR systems during this step are very diverse and many solutions have been proposed.
However, most of OMR systems first does a segmentation step and then apply recognition techniques to extract the correct symbol.
A simple way of segmenting a score is by first extracting graphical primitives like a line, blobs, circles \ldots and then joins these graphical primitives for the recognition stages.
Symbols can be extracted and recognize by using template matching techniques.
But these kind of techniques have many drawbacks as they are slow to compute and have a really low robustness when recognizing a symbol.
One way to recognize a symbol from a bounding box candidate is by computing simple operation that will result in simple features of the region of interest of the image and compare the results with those same features computed from symbols models.
This same philosophy can be used with different techniques by using symbol descriptors like centroids, Zernike moments, decision trees.


The use of classifiers is yet another method to recognize a music symbol and four different classifiers are compared in \cite{rebelo_optical_2009}.
Hidden Markov models have been extensively used for optical character recognition and speech recognition.
In \cite{pugin_optical_2006}, they have attempted to apply a hidden Markov model for recognizing very simple and old scores.
Their proposition has the interesting property to merge the segmentation task and the recognition task.
The use of simple neural network like a multi-layered perceptron also have been reviewed for recognizing music symbols.
The classic backward-propagation algorithm has been used for the training algorithm.
The results were disappointing as they were outperformed by some simple classifiers as the k-NN classifiers.
Nowadays, new neural network architecture have been proposed in similar domain like optical character recognition, speech recognition or computer vision, but they have never been used in the field of OMR.
The k-nearest neighbour algorithm used in this context is the most simple classification algorithm used.
They implemented it using euclidean distance and it gave the second best result after SVM.
Support vector machine have also been used for this task.
They used a radial basis function network and at the time of the study, it was the classifier that gave the best result.
All of these classifiers first needed an explicit segmentation phase except the HMM classifier.
For this internship we are looking for new way of recognizing broken and overlapping symbols and one of our hypothesis is that by merging the segmentation and recognition phase, we will improve the recognition rate.
That is why we will review more in detail the HMM proposition later in this work.

\subsubsection{Music notation reconstruction}

The music notation reconstruction has the specific task to interpret the spatial relationship between different primitives or symbol recognized.
This kind of algorithm has to deal with the complex two dimensional structure of music notation, as a consequence the positional information of a music symbol is very important as well as the context of the symbol.

OMR system has used fuzzy models or grammars to formalize musical notation.
We can differentiate two kinds of grammars.
Rule based grammar, or graph based grammar.
In this work, we will focus on rule based grammar by presenting the DMOS system \cite{couasnon_dmos_2001} as it is the system that will be used during this internship.

\subsection{DMOS: Generic Document Recognition Method}

DMOS, "Description and MOdification of Segmentation", is a general method for the recognition of structured documents.
Its main purpose is to separate the semantic and graphic knowledge of the program that do the recognition task because of the well known paradox in computer vision that there is a discrepancy between the way knowledge describe an object and the way objects have to be recognized \cite{couasnon_dmos_2001}.
Its main objective is to describe a generic method for recognizing any structured documents.

The system implemented in \cite{couasnon_dmos_2001} is mainly separated in two parts.
First, the system use a grammar for formalizing the syntax and graphical organization of the documents.
This grammar is derived from the EPF grammar (Enhanced Position Formalism) and is expressed in a Prolog dialect called $\lambda Prolog$.
There are two levels of grammar:
\begin{itemize}
  \item A physical level: formalization of the graphical organization of the documents.
  \item A logical level: work on the semantic level of the document.
\end{itemize}
The grammar manipulate \textit{terminals} that are simple graphical units like a line or a little connected component.
Its by agglomerating these terminals that the grammar construct complex structure that will describe the graphical and semantical organization of the document.
For this to work, the article introduce new spatial and logical operator that allows them to add expressivity to the grammar.

The second part is where the originality of the approach is found.
Classical computer vision system that use a grammar only use the grammar at the end of the recognition chain.
Some tool for segmenting and recognition is used and then symbols that are recognized are fed into the grammar for possible recognition errors and reconstruction of the semantic notation of the document.
In the DMOS system presented by \cite{couasnon_dmos_2001}, the grammar totally guide the segmentation and recognition of the document.
The grammar is compiled into appropriate parsers that do the low-level image recognition of the documents.
It's the grammar that decide on how to segment the document, then feed the candidates into classifiers that will confirm the label of the symbol.
The grammar can then check if the recognition is consistent, and if it is not, it can redo the segmentation step for finding a better solution.
The grammar can therefore use the context for segmentation \textit{and} recognition tasks.

This system has been initially implemented for recognizing orchestral scores and has been validated on the task of recognizing around 5000 old military forms.
However this system is still having difficulties on recognizing broken and overlapping symbols in scores.
Since the proposition of the orchestral scores recognition using DMOS, many new techniques in computer vision for the segmentation and recognition task have been found.
We will now review some of those techniques.

\section{Merging recognition and segmentation phase for classification of music symbols}

Our hypothesis is that by merging the segmentation task at the symbol level, we will improve the recognition rate of our system.
An attempt has been done in this direction by using a hidden markov model for recognizing old and very simple scores.

\subsection{Hidden Markov Model}

Authors in \cite{pugin_optical_2006} present a hidden markov model for recognizing old and very simple scores.
They decided to avoid the staff removal step and the segmentation step because they considered that these steps are an important source of errors.
They trained their model with a dataset of 240 pages of music scores containing 175 symbols.
The partitions were manually annotated with graphical informations.
The recognition process used imitate speech recognition as they used a sliding windows for scanning the score.
They simplified the problem by only having a succession of notes from left to right.
As a consequence, their system couldn't handles chords because the model was sequential and unidirectional.
They computed 4 to 40 features from the raw score image and used the Baum-Welch algorithm for training the HMM.
The recognition rate obtained was around 96\% but this rate is highly dependent of the feature chose, the sliding windows width, \ldots

This method has the advantage to avoid explicit segmentation by using a hidden markov model.
But this model will be hard to be applied on more complex score as they have simplified the problem by using only unidimensional score.
Indeed the objective of this internship is to work on big and complex orchestral score.
The HMM is also known for having difficulties to use context information because of their architecture principle.
This is why, we will introduce next another architecture used on optical character recognition and speech recognition that avoid totally the segmentation during the training phase and have no problem with using long-term dependency.


\subsection{Multi-Dimensional Long Short-Term Memory Recurrent Neural Network}

In the Optical Character Recognition field, a new kind of architecture has been presented by Graves and Schmidhuber \cite{graves_offline_2009}.
They used Long Short-Term Memory Recurrent Neural Network (LSTM RNN) \cite{hochreiter_long_1997} for dealing with long term dependency.
The context information has been handled by a Multi-Dimensional Recurrent Neural Network (MD RNN) and they avoided explicit segmentation by using a Connectionist Temporal Classification (CTC) output layer \cite{graves_connectionist_2006}.
An image is not just a one dimensional sequence of data needed for the input of the CTC, so they used a specific type of architecture for reducing a two dimensional image to a one dimensional sequence.

\subsubsection{Long Short-Term Memory Recurrent Neural Network}

RNN is a powerful neural network that are designed for working with sequence.
However, simple RNN are known for having the vanishing and exploding gradient problem.
Indeed, when training a RNN with the classical gradient descent algorithm, each time-step is like a new layer to network, making it a very deep network.
Long Short-Term Memory Recurrent Neural Network is designed to resolve this problem.

To control the variation of the gradient, they truncate the gradient during the training phase.
They used a "constant error carrousels" to ensure constant error flow through the network.
The base unit of the network is not a neuron but a memory cell constituted of two gates.
First, a multiplicative input gate unit to protect the memory stored in the unit from irrelevant input.
Second, a multiplicative output gate used to protect other units from the irrelevant memory of the unit.
Each of these units have to be properly trained for respectively learn which error to release or to keep.

In \cite{hochreiter_long_1997}, they presented this kind of RNN using three fully connected layers: one input layer, one hidden layer, one output layer.
The main advantage of the LSTM RNN is to be able to deal naturally with long-term dependency in the data sequence.
Next we will see how to use the context when working with two dimensional data like an image.

\subsubsection{Multi-Dimensional Recurrent Neural Network (MD RNN)}

The novelty presented in \cite{graves_offline_2009} is the use of Multi-Dimensional RNN.
This network is a generalization of Bi-Directional Neural Network.
Bi-directional neural network is used for using past and future context for 1 dimensional data by adding recurrent connection to the previous sample and the future sample.
Similarly, MD RNN generalize this principle for N dimensions.
For example, an image is a two dimensional data, so a MD RNN used on an image adds 4 recurrent connections to all spatial directions.
To do this, \cite{graves_offline_2009} describe a four layer network where each layer scans from each corner of the image.
This way, it allows the network to create a flexible internal representation of the surrounding context.
Furthermore, this kind of networks are very robust to local distortion, making it an ideal system for recognizing handwritten data.
The MD RNN is trained with the backpropagation algorithm generalized to N dimensions.

This kind of network could be very interesting for recognizing musical symbols, specially handwritten symbols because of their robustness to distortion.
Furthermore, the context is extremely important for recognizing a symbol in a score.
However, it is still early to say if this kind of network could learn the complex structure of a score.

\subsubsection{Connectionist Temporal Classification (CTC)}

The work of \cite{graves_connectionist_2006} introduced the Connectionist Temporal Classification layer that allows a new way of training RNN for labelling unsegmented sequence data directly.
The CTC layer is an output layer designed for one dimensional sequence labelling.
The principle is to train the network to estimate the conditional probabilities of all the possible labellings.
If the alphabet used during a recognition contains N symbols, the CTC layer will contain N+1 symbols because it adds the blank output.
The output of a CTC layer is normalized using a softmax function.
Then, all repetitions and blanks are removed to form blocks of symbols.
Training is done with the back propagation in time algorithm with the negative log probability function as the objective function.

The main advantage of this proposition is the fact that the network can be trained without presegmenting the ground truth data, or postprocessing the output of the network.
However in the context of OMR, the major problem is that the CTC layer is designed to label one dimensional sequence data, and we have already pointed out that a score is a complex two dimensional structure.
What we need from the output of an OMR system is the label of the symbol, but also his exact coordinate in the image.
This problem is further developed in the next section where the authors of \cite{graves_offline_2009} show how they transform an image into a one dimensional sequence of data.

\subsubsection{Network Hierarchy}

We will now present the overall hierarchy used in \cite{graves_offline_2009} for their OCR system.
The most common way for doing image recognition is not to directly work on the pixel level of the image but to first extract \textit{features} of the image and then do the recognition phase.
A feature can be describe as a small piece of information extracted from the image.
The authors use this same principle however they have a hierarchical approach for feature extraction.
This allows them to build complex visual properties from the raw image.
In computer vision, this kind of structure is called an \textit{inverted pyramid structure}: small layers at the bottom of the hierarchy and large layer at the top of the hierarchy for creating an efficient network.

The hierarchical structure is composed by interleaving MDLSTM layers with feedforward network.
The activation of MDLSTM layers are gathered into blocks.
The purpose of these blocks is mainly to have a local contextual information and also to reduce the area of the activation arrays: at each level of the network, the vertical axis of the data is reduced to finally form a one dimensional sequence from a two dimensional block of data.
This is called \textit{subsampling}.
For the specific application of OCR, authors have found that three layers of MDLSTM/Feedforward gives the best results.

This architecture has a dual property of reducing a two dimensional image into a one dimensional sequence and to be able to train and use the entire system without segmenting the data.
The first characteristic is not interesting in the context of OMR because we already said that a score is not a one dimensional sequence of data.
However, the second characteristic is very likely to improve the recognition of broken and overlapping symbols.
We will now see how this architecture can be used for complex recognition process as the Maurdor challenge.

\subsection{A2IA recognition system proposition}

We already highlighted the fact that OCR is a similar to OMR but it has the main difference is that the structure to recognize is much simpler in OCR.
However, this is only true at the symbol level.
In fact, if we zoom out and consider an entire document, the recognition process can be much more complex.
For example, the Maurdor challenge is a computer vision and document recognition contest with some very hard data to recognized.
The A2IA team has submit an entire document processing chain and ranked first at the second Maurdor evaluation for both printed and handwritten text recognition for French, English and Arabic \cite{moysset_a2ia_2014}.
The document processing chain is composed of:
\begin{itemize}
  \item Document layout analysis
  \item Write type identification
  \item Language identification
  \item Text recognition
  \item Logical organization extraction
  \item Information extraction
\end{itemize}
They used the recognition system previously explained for the text recognition part, with little changes:
\begin{itemize}
  \item Adapted the sub-sampling filter size to fit the image resolution.
  \item Tuned hidden layer sizes for the dataset
\end{itemize}
One important improvement to the training phase was the use of dropout.

However, the interesting part here is their techniques for automatically prepare the data for the training phase.
Indeed, instead of just recognizing lines of text, a paragraph of text was given to the input of the text recognition module.
That's why they used an automatic system for the alignment of annotations and images of lines of text.
They used a line detection algorithm to extract lines of text and they applied a constrained line recognition system to match the lines image to a part of the ground-truth text.
In the context of this internship, we could also use the powerful grammar present in the DMOS system to roughly segment a score and spot zones with broken and overlapping symbols.
Then, we could feed these zones to a recognition system like the one we saw previously.

\section{Object Recognition Techniques}

After reviewing some techniques used in OCR and Speech Recognition, it could be interesting to see what kinds of recognition systems are used for object recognition in an image.
Nowadays, deep neural networks are widely used in object recognition and are known to be the state of the art in image recognition \cite{erhan_scalable_2014}.
We will also review another proposition \cite{ba_multiple_2014} that concentrate on modelling an effective visual attention model.

\subsection{Deep Neural Network}

In \cite{erhan_scalable_2014}, they used a deep neural network for detecting and localizing multiple scalable object in an image.
A common way to localize different object in an image is to train one object detector by class to recognize.
As the number of class grows, it become computationally difficult to scale up the system.
The originality of this works is to train one single Deep Neural Network that is \textit{class agnostic} and use it to localize any object of interest in an image.
This deep neural network is structured with multiple convolutional neural network and multiple max-pooling layer.
The output is normalized with a soft-max layer.
The recognition system proposed in \cite{erhan_scalable_2014} has the capability to output a bounding box to localize objects and a confidence score about the label of all objects detected.
The strength of this proposition is its property to handle naturally multiple instance of an object in an image.

In the context of OMR, this kind of network could be interesting as it can localize precisely with a bounding box an object in an image.
The fact that the bounding box is scalable is also interesting because there are multiple musical symbols that can used with different sizes.
However, the training phase is still a problem, because training data still have to be graphically annotated to point the ground-truth location of the object.
In OMR, such database doesn't exist.
In fact, OMR database are not well developed.
There are some music symbols databases used for training simple classifiers and databases of images of music scores exist with often the semantical transcription of the score using the MusicXML format or the Midi format but the graphical annotation of each symbols is not existent.

To address this problem, we will now introduce another use of RNN applied for Object Recognition.

\subsection{Multiple Object Recognition with Visual Attention}

Authors of \cite{ba_multiple_2014} proposed an attention-based model inspired from the human vision used for recognizing multiple objects in images.
Studies on human vision show that a human gradually construct its environment representation by focusing its attention on successive small parts of the image.
This principle is used here by using a Deep Recurrent Neural Network that process an image by taking \textit{glimpse} at different resolutions.
A glimpse is a small part of the image centered on a special location.
Furthermore, they used reinforcement learning to train the network to learn on how to scan the image.
The model can learn to localize and recognize multiple objects although it was only trained with class labels.
They evaluate the system by using this model to transcribe house number from Google Street View.
This model showed to be more accurate than state of the art convolutional networks although the model is using fewer parameters and less computations.

The Visual Attention model process the image in N sequential steps.
For each step, the model scans a new location and extract a glimpse at this location.
From this glimpse, the model update its internal representation of the image.
The model use a special classifier for recognizing objects.
Finally, the model output a new location to scan from.
The model is divided successively in sub-component and each of those components is a neural network.
The first network is the glimpse network used to extract features from the glimpse with two input layer: a convolutional layer that take a glimpse as an input and a fully connected layer that take the location of the glimpse as an input.
These two layers are then combined by multiplying the output of each layer.
The next network is a recurrent network composed of two recurrent layer composed of LSTM units.
It's work is to aggregate informations extracted from successive glimpses while preserving the spatial information.
Then a third network called the emission network is used to predict the location of the next glimpse.
A context network is used to compute an initial state for the system and provide the location of the first glimpse.
Finally a classification network is used to output a prediction from the first RNN layer.
It is composed of a fully connected hidden layer and a softmax output layer.

This kind of model could be useful in our OMR system.
The fact that this model can locate and recognize symbol although the network was only trained with class labels in interesting because in OMR, we only have databases containing class labels symbols.
Furthermore, this system can locate an object in an image, making it ideal for an OMR system.
Without having this system learn how to read a complex score, we could use the grammar to make a first rough segmentation and then use this recognition system for locating accidentals, key signatures, time signature, silences \ldots

\section{Conclusion}

A renewed interest is showing toward OMR in the computer vision and pattern recognition research field because it has still many challenges to overcome.
While OCR is now very advanced and has human like results, we still have many difficulties in recognizing music scores because of its complex structure and variety of symbols.
Many solutions have been proposed for every step of OMR: preprocessing, staff removal, music symbols segmentation and recognition, music notation reconstruction.
Especially with the DMOS system that will be used in this internship, its powerful grammar is capable of guiding the segmentation, recognition and reconstruction of the music score.
However, the recognition of broken and overlapping symbols are still very difficult to handle.
The principle hypothesis of this study is that by avoiding explicit segmentation for the segmentation 


\section*{References}

\bibliographystyle{plain}
\bibliography{model}
\end{document}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
